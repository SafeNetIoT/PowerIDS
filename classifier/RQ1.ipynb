{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f247fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd12c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadPow(attack=None):\n",
    "    cwd = os.getcwd()\n",
    "    directory = os.path.join(cwd,\"power_csv\")\n",
    "    pow_hm = {}\n",
    "    powers,labels=[],[]\n",
    "    device=\"\"\n",
    "    for path2 in os.scandir(pathlib.Path(directory)):\n",
    "        if not path2.is_dir(): continue\n",
    "        for path in os.scandir(pathlib.Path(path2)):\n",
    "            if not path.is_dir(): continue\n",
    "            powers_list=[]\n",
    "            labels_list=[]\n",
    "            device = os.path.basename(path)\n",
    "            for file in os.scandir(pathlib.Path(path)):\n",
    "                csv = os.path.basename(file)\n",
    "                if \"csv\" in csv:\n",
    "                    if attack:\n",
    "                        if attack in csv:\n",
    "                            df = pd.read_csv(file)\n",
    "                            df = df[:int(len(df)*0.8)]\n",
    "                            powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                            labels_list.append(df.iloc[:,2].to_numpy())\n",
    "                    else:\n",
    "                        df = pd.read_csv(file)\n",
    "                        df = df[:int(len(df)*0.8)]\n",
    "                        powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                        labels_list.append(df.iloc[:,2].to_numpy())\n",
    "            if powers_list:\n",
    "                powers=np.concatenate(powers_list)\n",
    "                labels=np.concatenate(labels_list)\n",
    "                pow_hm[device]=(powers,labels)\n",
    "    return pow_hm\n",
    "\n",
    "def loadPowTest(attack=None):\n",
    "    cwd = os.getcwd()\n",
    "    directory = os.path.join(cwd,\"power_csv\")\n",
    "    pow_hm = {}\n",
    "    powers,labels=[],[]\n",
    "    device=\"\"\n",
    "    for path2 in os.scandir(pathlib.Path(directory)):\n",
    "        if not path2.is_dir(): continue\n",
    "        for path in os.scandir(pathlib.Path(path2)):\n",
    "            if not path.is_dir(): continue\n",
    "            powers_list=[]\n",
    "            labels_list=[]\n",
    "            device = os.path.basename(path)\n",
    "            for file in os.scandir(pathlib.Path(path)):\n",
    "                csv = os.path.basename(file)\n",
    "                if \"csv\" in csv:\n",
    "                    if attack:\n",
    "                        if attack in csv:\n",
    "                            df = pd.read_csv(file)\n",
    "                            df = df[int(len(df)*0.8):]\n",
    "                            powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                            labels_list.append(df.iloc[:,2].to_numpy())\n",
    "                    else:\n",
    "                        df = pd.read_csv(file)\n",
    "                        df = df[int(len(df)*0.8):]\n",
    "                        powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                        labels_list.append(df.iloc[:,2].to_numpy())\n",
    "            if powers_list:\n",
    "                powers=np.concatenate(powers_list)\n",
    "                labels=np.concatenate(labels_list)\n",
    "                pow_hm[device]=(powers,labels)\n",
    "    return pow_hm\n",
    "dic = loadPow()\n",
    "dic_test = loadPowTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(series, labels, w=30, s=10):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(0, len(series) - w, s):\n",
    "        window_vals  = series[i:i+w]\n",
    "        window_labels = labels[i:i+w]\n",
    "        X.append(window_vals)\n",
    "        ones = window_labels.sum()\n",
    "        y.append(int(ones >= (w / 2)))             # 1 if â‰¥ half else 0\n",
    "        \n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32) \n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1eed64-415f-4e92-8fea-126208b35833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(windows):\n",
    "    feats = []\n",
    "    for w in windows:\n",
    "        feats.append([\n",
    "            torch.mean(w),\n",
    "            torch.std(w),\n",
    "            torch.min(w),\n",
    "            torch.max(w),\n",
    "            torch.median(w)\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    return np.array(feats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6707d8-976a-4514-8f59-0dd9e3d1a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall performance\n",
    "dic,dic_test=loadPow(),loadPowTest()\n",
    "results=[]\n",
    "for device in dic.keys():\n",
    "    scaler=StandardScaler()\n",
    "    X_raw,y_raw = np.array(dic[device][0]).reshape(-1, 1) , np.array(dic[device][1])\n",
    "    X_scaled = scaler.fit_transform(X_raw).flatten() \n",
    "    X_train,y_train = make_windows(X_scaled, y_raw)\n",
    "    X_test,y_test = np.array(dic_test[device][0]).reshape(-1, 1), np.array(dic_test[device][1])  \n",
    "    X_test = scaler.transform(X_test).flatten()\n",
    "    X_test,y_test = make_windows(X_test, y_test)\n",
    "    X_train_feats = extract_features(X_train)\n",
    "    X_test_feats  = extract_features(X_test)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "    clf.fit(X_train_feats, y_train)\n",
    "    y_pred = clf.predict(X_test_feats)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    results.append([device, acc, f1_macro])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"device\", \"accuracy\", \"f1_macro\"])\n",
    "df_results.to_csv(\"overall.csv\", index=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5ae04-bce3-4247-b9a4-755a5dfc26b1",
   "metadata": {},
   "source": [
    "## Per Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d8504-1ba7-4be3-989f-c26fb3de0aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#per attack performance\n",
    "attacks=[\"icmp\",\"os\",\"port\",\"syn\"]\n",
    "results=[]\n",
    "for attack in attacks:\n",
    "    dic,dic_test=loadPow(attack),loadPowTest(attack)\n",
    "    print(attack)\n",
    "    for device in dic.keys():\n",
    "        scaler=StandardScaler()\n",
    "        X_raw,y_raw = np.array(dic[device][0]).reshape(-1, 1) , np.array(dic[device][1])\n",
    "        X_scaled = scaler.fit_transform(X_raw).flatten() \n",
    "        X_train,y_train = make_windows(X_scaled, y_raw)\n",
    "        X_test,y_test = np.array(dic_test[device][0]).reshape(-1, 1), np.array(dic_test[device][1])  \n",
    "        X_test = scaler.transform(X_test).flatten()\n",
    "        X_test,y_test = make_windows(X_test, y_test)\n",
    "        X_train_feats = extract_features(X_train)\n",
    "        X_test_feats  = extract_features(X_test)\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "        clf.fit(X_train_feats, y_train)\n",
    "        y_pred = clf.predict(X_test_feats)\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        acc=accuracy_score(y_test, y_pred)\n",
    "        results.append([ attack,device, acc, f1_macro])\n",
    "\n",
    "# Save to CSV\n",
    "df_results = pd.DataFrame(results, columns=[ \"attack\",\"device\", \"accuracy\", \"f1_macro\"])\n",
    "df_results\n",
    "df_results.to_csv(\"per_attack.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c9a6a-bbec-43e9-b1f8-dd90b0ce1fb2",
   "metadata": {},
   "source": [
    "## Feature ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b9573-e503-4b22-a74b-f26390507bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full set of features if needed\n",
    "def extract_features(windows):\n",
    "    feats = []\n",
    "\n",
    "    for w in windows:\n",
    "        # Convert tensor -> numpy\n",
    "        w_np = w.detach().cpu().numpy().astype(float)\n",
    "        n = len(w_np)\n",
    "\n",
    "        # ---------------------------\n",
    "        # 1. Baseline Features (5)\n",
    "        # ---------------------------\n",
    "        mean = np.mean(w_np)\n",
    "        std = np.std(w_np)\n",
    "        mn = np.min(w_np)\n",
    "        mx = np.max(w_np)\n",
    "        med = np.median(w_np)\n",
    "\n",
    "        # ---------------------------\n",
    "        # 2. Temporal Features (6)\n",
    "        # ---------------------------\n",
    "\n",
    "        # Successive diffs\n",
    "        diffs = np.diff(w_np)\n",
    "        abs_diffs = np.abs(diffs)\n",
    "\n",
    "        masc = np.mean(abs_diffs) if n > 1 else 0.0\n",
    "        line_length = np.sum(abs_diffs) if n > 1 else 0.0\n",
    "\n",
    "        # Autocorrelation lag-1\n",
    "        if n > 1:\n",
    "            acf1 = np.corrcoef(w_np[:-1], w_np[1:])[0,1]\n",
    "        else:\n",
    "            acf1 = 0.0\n",
    "        acf1 = np.nan_to_num(acf1)\n",
    "\n",
    "        # Autocorrelation lag-5\n",
    "        if n > 5:\n",
    "            acf5 = np.corrcoef(w_np[:-5], w_np[5:])[0,1]\n",
    "        else:\n",
    "            acf5 = 0.0\n",
    "        acf5 = np.nan_to_num(acf5)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zcr = np.mean((w_np[:-1] * w_np[1:]) < 0)\n",
    "\n",
    "        # Slope (linear regression on index positions)\n",
    "        idx = np.arange(n)\n",
    "        slope = np.polyfit(idx, w_np, 1)[0]\n",
    "\n",
    "        # ---------------------------\n",
    "        # 3. Spectral Features (5)\n",
    "        # ---------------------------\n",
    "        # One-sided FFT magnitude squared = PSD\n",
    "        fft_vals = np.fft.rfft(w_np - mean)\n",
    "        psd = np.abs(fft_vals)**2 + 1e-12\n",
    "        freqs = np.fft.rfftfreq(n, d=1.0)\n",
    "\n",
    "        psd_sum = np.sum(psd)\n",
    "\n",
    "        # Spectral centroid\n",
    "        centroid = np.sum(freqs * psd) / psd_sum\n",
    "\n",
    "        # Spectral bandwidth\n",
    "        bandwidth = np.sqrt(np.sum(((freqs - centroid)**2) * psd) / psd_sum)\n",
    "\n",
    "        # Spectral flatness\n",
    "        flatness = np.exp(np.mean(np.log(psd))) / np.mean(psd)\n",
    "\n",
    "        # Spectral entropy\n",
    "        p = psd / psd_sum\n",
    "        entropy = -np.sum(p * np.log2(p))\n",
    "\n",
    "        # Dominant frequency amplitude\n",
    "        dom_amp = np.max(psd)\n",
    "\n",
    "        # Collect all features\n",
    "        feats.append([\n",
    "            mean, std, mn, mx, med,     # 5 baseline\n",
    "            masc, acf1, acf5, zcr, line_length, slope,   # 6 temporal\n",
    "            centroid, bandwidth, flatness, entropy, dom_amp  # 5 spectral\n",
    "        ])\n",
    "\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "X_train_feats = extract_features(X_train)\n",
    "X_test_feats  = extract_features(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657446f-a25d-45ee-be40-3c1ff49bd170",
   "metadata": {},
   "source": [
    "## Idle vs Active seperation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf55a0-be95-4a54-b1ec-c22dbdbc5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPow(attack=None):\n",
    "    cwd = os.getcwd()\n",
    "    directory = os.path.join(cwd,\"power_csv\")\n",
    "    pow_hm = {}\n",
    "    powers,labels=[],[]\n",
    "    device=\"\"\n",
    "    for path2 in os.scandir(pathlib.Path(directory)):\n",
    "        if not path2.is_dir(): continue\n",
    "        for path in os.scandir(pathlib.Path(path2)):\n",
    "            if not path.is_dir(): continue\n",
    "            powers_list=[]\n",
    "            labels_list=[]\n",
    "            device = os.path.basename(path)\n",
    "            for file in os.scandir(pathlib.Path(path)):\n",
    "                csv = os.path.basename(file)\n",
    "                if \"csv\" in csv:\n",
    "                    if attack:\n",
    "                        if attack in csv and \"active\" in csv:\n",
    "                            df = pd.read_csv(file)\n",
    "                            df = df[:int(len(df)*0.8)]\n",
    "                            powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                            labels_list.append(df.iloc[:,2].to_numpy())\n",
    "                    else:\n",
    "                        df = pd.read_csv(file)\n",
    "                        df = df[:int(len(df)*0.8)]\n",
    "                        powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                        labels_list.append(df.iloc[:,2].to_numpy())\n",
    "            if powers_list:\n",
    "                powers=np.concatenate(powers_list)\n",
    "                labels=np.concatenate(labels_list)\n",
    "                pow_hm[device]=(powers,labels)\n",
    "    return pow_hm\n",
    "\n",
    "dic_active= loadPow()\n",
    "\n",
    "def loadPow(attack=None):\n",
    "    cwd = os.getcwd()\n",
    "    directory = os.path.join(cwd,\"power_csv\")\n",
    "    pow_hm = {}\n",
    "    powers,labels=[],[]\n",
    "    device=\"\"\n",
    "    for path2 in os.scandir(pathlib.Path(directory)):\n",
    "        if not path2.is_dir(): continue\n",
    "        for path in os.scandir(pathlib.Path(path2)):\n",
    "            if not path.is_dir(): continue\n",
    "            powers_list=[]\n",
    "            labels_list=[]\n",
    "            device = os.path.basename(path)\n",
    "            for file in os.scandir(pathlib.Path(path)):\n",
    "                csv = os.path.basename(file)\n",
    "                if \"csv\" in csv:\n",
    "                    if attack:\n",
    "                        if attack in csv and \"idle\" in csv:\n",
    "                            df = pd.read_csv(file)\n",
    "                            df = df[:int(len(df)*0.8)]\n",
    "                            powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                            labels_list.append(df.iloc[:,2].to_numpy())\n",
    "                    else:\n",
    "                        df = pd.read_csv(file)\n",
    "                        df = df[:int(len(df)*0.8)]\n",
    "                        powers_list.append(df.iloc[:,1].to_numpy())\n",
    "                        labels_list.append(df.iloc[:,2].to_numpy())\n",
    "            if powers_list:\n",
    "                powers=np.concatenate(powers_list)\n",
    "                labels=np.concatenate(labels_list)\n",
    "                pow_hm[device]=(powers,labels)\n",
    "    return pow_hm\n",
    "dic_idle = loadPow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b6b51-161a-4306-929d-30ec25f784dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
